{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Medical Entity Recognition with Pretrained Transformers**","metadata":{}},{"cell_type":"markdown","source":"# Project Description:\nIn this notebook I aim to explore the capabilities of pretrained transformer models, with a particular focus on BERT (Bidirectional Encoder Representations from Transformers), for the task of identifying medical entities within textual data.\n\nMedical entity recognition is a critical component of various healthcare applications, including clinical decision support systems, electronic health record analysis, and biomedical research.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"markdown","source":"The [NCBI Disease](https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/)  corpus is a valuable dataset consisting of 793 PubMed abstracts that have been annotated with 6,892 disease mentions. It serves as a valuable resource for researchers and developers working on tasks related to disease recognition and information extraction from biomedical literature.\n\nThe NCBI Disease corpus offers opportunities for training and evaluating models in the field of natural language processing and machine learning. It enables tasks such as disease recognition, named entity recognition, entity linking, and information extraction from scientific articles.\n\nBy leveraging the NCBI Disease corpus, researchers and developers can advance the state-of-the-art in biomedical text mining, contribute to the development of clinical decision support systems, and facilitate the discovery of novel insights and knowledge in the field of medicine.\n(https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/annotationprocess.png)","metadata":{}},{"cell_type":"markdown","source":"![The NCBI Disease Corpus](https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/annotationprocess.png)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:51:40.934848Z","iopub.execute_input":"2023-05-21T11:51:40.935252Z","iopub.status.idle":"2023-05-21T11:51:41.965865Z","shell.execute_reply.started":"2023-05-21T11:51:40.935223Z","shell.execute_reply":"2023-05-21T11:51:41.964713Z"}}},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('ncbi_disease')","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:29:07.980262Z","iopub.execute_input":"2023-05-21T11:29:07.982146Z","iopub.status.idle":"2023-05-21T11:29:13.707837Z","shell.execute_reply.started":"2023-05-21T11:29:07.982105Z","shell.execute_reply":"2023-05-21T11:29:13.706893Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"232176afb3394409af0fdbcb0bf739df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"055a50f7f42443d49f614e5134ea4084"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset ncbi_disease/ncbi_disease (download: 1.47 MiB, generated: 3.04 MiB, post-processed: Unknown size, total: 4.52 MiB) to /root/.cache/huggingface/datasets/ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b646fd025d0840abb74a496bc3ef7dec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/284k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e301690ed9241f5a2617f3273050252"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/51.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b6723ee06c740d2a4f38997c434e811"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/52.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d949cf843692433a9d29d12ada00d935"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3af87d9f493a44e096fe3cdea6d7aba5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5433 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/924 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/941 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset ncbi_disease downloaded and prepared to /root/.cache/huggingface/datasets/ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a786d625965e4749b20d0978327247b5"}},"metadata":{}}]},{"cell_type":"markdown","source":"\n## The NCBI disease corpus is fully annotated at the mention and concept level to serve as a research resource for the biomedical natural language processing community.\n\n\n### Corpus Characteristics\n\n793 PubMed abstracts\n6,892 disease mentions\n790 unique disease concepts\nMedical Subject Headings (MeSH®)\nOnline Mendelian Inheritance in Man (OMIM®)\n91% of the mentions map to a single disease concept\ndivided into training, developing and testing sets.\n### Corpus Annotation\nFourteen annotators\nTwo-annotators per document (randomly paired)\nThree annotation phases\nChecked for corpus-wide consistency of annotations\n\nThe abstracts are split into sentences, which already have been tokenized for us. There are 5433 sentences in the training data, 924 in the validation data and another 941 in the test data.","metadata":{}},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:35:06.934570Z","iopub.execute_input":"2023-05-21T11:35:06.935060Z","iopub.status.idle":"2023-05-21T11:35:06.946929Z","shell.execute_reply.started":"2023-05-21T11:35:06.935020Z","shell.execute_reply":"2023-05-21T11:35:06.945988Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 5433\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 924\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 941\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"splits = list(dataset.keys())\nnum_examples = [dataset[s].num_rows for s in splits]\n\nfor split, num in zip(splits, num_examples):\n    print(f\"{split}: {num} examples\")\n\ntotal_examples = sum(num_examples)\nprint(\"Total examples:\", total_examples)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:04:01.735577Z","iopub.execute_input":"2023-05-21T12:04:01.736661Z","iopub.status.idle":"2023-05-21T12:04:01.743413Z","shell.execute_reply.started":"2023-05-21T12:04:01.736617Z","shell.execute_reply":"2023-05-21T12:04:01.742385Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"train: 5433 examples\nvalidation: 924 examples\ntest: 941 examples\nTotal examples: 7298\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The first training example is the sentence 'Identification of APC2, a homologue of the adenomatous polyposis coli tumour suppressor.' The phrase 'adenomatous polyposis coli tumour' has been labeled as a disease.","metadata":{}},{"cell_type":"code","source":"dataset[\"train\"][0] #first example","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:36:01.955705Z","iopub.execute_input":"2023-05-21T11:36:01.956092Z","iopub.status.idle":"2023-05-21T11:36:01.966678Z","shell.execute_reply.started":"2023-05-21T11:36:01.956061Z","shell.execute_reply":"2023-05-21T11:36:01.965538Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'tokens': ['Identification',\n  'of',\n  'APC2',\n  ',',\n  'a',\n  'homologue',\n  'of',\n  'the',\n  'adenomatous',\n  'polyposis',\n  'coli',\n  'tumour',\n  'suppressor',\n  '.'],\n 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0]}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"markdown","source":"I choose one of the available PubMedBERTs — BERT models that have been pretrained on abstracts (and in this case, also full texts) from PubMed. I start by getting the tokenizer that was used for pretraining this model, because texts need to be tokenized in exactly the same manner!","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nMODEL = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:37:06.439778Z","iopub.execute_input":"2023-05-21T11:37:06.440354Z","iopub.status.idle":"2023-05-21T11:37:09.586588Z","shell.execute_reply.started":"2023-05-21T11:37:06.440321Z","shell.execute_reply":"2023-05-21T11:37:09.585650Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f00a47627154f8aa079bc39a5c012ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ce5369bb79a4ca581fe309d0b423f2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12a868b072df4e7dbe042e22de57a74d"}},"metadata":{}}]},{"cell_type":"markdown","source":"Then I used this tokenizer to tokenize the texts (every sentence in our corpus is a list of words, so I need to tell the tokenizer the text has already been split into words). In addition, I'll  pad and truncate the texts. Sentences that are longer than 256 tokens will be truncated, and all sentences will be padded to the length of the (resulting) longest one.","metadata":{}},{"cell_type":"code","source":"train_texts = [item[\"tokens\"] for item in dataset[\"train\"]]\ndev_texts = [item[\"tokens\"] for item in dataset[\"validation\"]]\ntest_texts = [item[\"tokens\"] for item in dataset[\"test\"]]\n\ntrain_texts_encoded = tokenizer(train_texts, padding=True, truncation=True, max_length=256, is_split_into_words=True)\ndev_texts_encoded = tokenizer(dev_texts, padding=True, truncation=True, max_length=256, is_split_into_words=True)\ntest_texts_encoded = tokenizer(test_texts, padding=True, truncation=True, max_length=256, is_split_into_words=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:41:04.515972Z","iopub.execute_input":"2023-05-21T11:41:04.516644Z","iopub.status.idle":"2023-05-21T11:41:06.722910Z","shell.execute_reply.started":"2023-05-21T11:41:04.516609Z","shell.execute_reply":"2023-05-21T11:41:06.721962Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"I have 3 lists of `Encoding`s, which contain all information that model needs, - the ids of the tokens, their type id, and their attention mask. ","metadata":{}},{"cell_type":"code","source":"train_texts_encoded[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:42:01.354670Z","iopub.execute_input":"2023-05-21T11:42:01.355069Z","iopub.status.idle":"2023-05-21T11:42:01.361089Z","shell.execute_reply.started":"2023-05-21T11:42:01.355039Z","shell.execute_reply":"2023-05-21T11:42:01.359936Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Encoding(num_tokens=138, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"},"metadata":{}}]},{"cell_type":"code","source":"train_texts_encoded[0].tokens[:20]","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:04:49.613253Z","iopub.execute_input":"2023-05-21T12:04:49.613633Z","iopub.status.idle":"2023-05-21T12:04:49.625088Z","shell.execute_reply.started":"2023-05-21T12:04:49.613602Z","shell.execute_reply":"2023-05-21T12:04:49.624030Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n 'identification',\n 'of',\n 'apc',\n '##2',\n ',',\n 'a',\n 'homologue',\n 'of',\n 'the',\n 'adenomatous',\n 'polyposis',\n 'coli',\n 'tumour',\n 'suppressor',\n '.',\n '[SEP]',\n '[PAD]',\n '[PAD]',\n '[PAD]']"},"metadata":{}}]},{"cell_type":"markdown","source":"To keep the size of the vocabulary manageable, unknown words have been split up into known subword parts, such as apc2, which has been split up into apc and ##2, where the ## indicates this is a continuation.","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing of labels","metadata":{}},{"cell_type":"markdown","source":"Because new tokens are different from the original tokens in the corpus, I can't just train the model on the original labels: I need to align the labels with the new tokens. Luckily the tokenizer also provides a list of offsets for every new token, where any can easily identify tokens that do not correspond to the original words. \n\nFor example, the offsets of the first training sentence tell us that `apc2` has been split up into two tokens, one for the first three characters of the word (indices 0 to, but not including, 3) and one for the last character of the word (indices 3 to, but not including, 4). \n\n\nAdditionally, I can also identified special tokens, such as `[CLS]` and `[PAD]` by the offset pair `[(0,0)]`. ","metadata":{}},{"cell_type":"code","source":"train_texts_encoded[0].offsets[:20]","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:48:51.743528Z","iopub.execute_input":"2023-05-21T11:48:51.743891Z","iopub.status.idle":"2023-05-21T11:48:51.750815Z","shell.execute_reply.started":"2023-05-21T11:48:51.743861Z","shell.execute_reply":"2023-05-21T11:48:51.749959Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[(0, 0),\n (0, 14),\n (0, 2),\n (0, 3),\n (3, 4),\n (0, 1),\n (0, 1),\n (0, 9),\n (0, 2),\n (0, 3),\n (0, 11),\n (0, 9),\n (0, 4),\n (0, 6),\n (0, 10),\n (0, 1),\n (0, 0),\n (0, 0),\n (0, 0),\n (0, 0)]"},"metadata":{}}]},{"cell_type":"markdown","source":"There are only three labels in the corpus — `O`, `B-disease` and `I-disease` — which have already been mapped to their index.","metadata":{}},{"cell_type":"code","source":"all_labels = list(set([label for item in dataset[\"train\"] for label in item[\"ner_tags\"]]))\nall_labels","metadata":{"execution":{"iopub.status.busy":"2023-05-21T11:54:20.176344Z","iopub.execute_input":"2023-05-21T11:54:20.176737Z","iopub.status.idle":"2023-05-21T11:54:20.853787Z","shell.execute_reply.started":"2023-05-21T11:54:20.176699Z","shell.execute_reply":"2023-05-21T11:54:20.852814Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[0, 1, 2]"},"metadata":{}}]},{"cell_type":"markdown","source":"For each sentence, I first create a numpy array filled with the label `-100`, a special label in the `transformers` library that will be ignored during training. Then I copy the original labels to the tokens at the start of every word. This means the remaining tokens of the word will still have the label `-100`. ","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef map_entities_to_tokens(items, encodings):\n    \n    labels = [item[\"ner_tags\"] for item in items]\n    offsets = [encoding.offsets for encoding in encodings]\n    encoded_labels = []\n    \n    for doc_labels, doc_offset in zip(labels, offsets):\n        #  empty array of -100\n        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n        arr_offset = np.array(doc_offset)\n\n        # set labels whose first offset position is 0 and the second is not 0\n        doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n        encoded_labels.append(doc_enc_labels.tolist())\n\n    return encoded_labels\n\ntrain_labels = map_entities_to_tokens(dataset[\"train\"], train_texts_encoded.encodings)\ndev_labels = map_entities_to_tokens(dataset[\"validation\"], dev_texts_encoded.encodings)\ntest_labels = map_entities_to_tokens(dataset[\"test\"], test_texts_encoded.encodings)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:06:49.213518Z","iopub.execute_input":"2023-05-21T12:06:49.213882Z","iopub.status.idle":"2023-05-21T12:06:51.076348Z","shell.execute_reply.started":"2023-05-21T12:06:49.213854Z","shell.execute_reply":"2023-05-21T12:06:51.075325Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"list(zip(train_texts_encoded[0].tokens[:20], train_labels[0][:20]))","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:07:21.917408Z","iopub.execute_input":"2023-05-21T12:07:21.917813Z","iopub.status.idle":"2023-05-21T12:07:21.926677Z","shell.execute_reply.started":"2023-05-21T12:07:21.917781Z","shell.execute_reply":"2023-05-21T12:07:21.925274Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[('[CLS]', -100),\n ('identification', 0),\n ('of', 0),\n ('apc', 0),\n ('##2', -100),\n (',', 0),\n ('a', 0),\n ('homologue', 0),\n ('of', 0),\n ('the', 0),\n ('adenomatous', 1),\n ('polyposis', 2),\n ('coli', 2),\n ('tumour', 2),\n ('suppressor', 0),\n ('.', 0),\n ('[SEP]', -100),\n ('[PAD]', -100),\n ('[PAD]', -100),\n ('[PAD]', -100)]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Setting up the dataset","metadata":{}},{"cell_type":"markdown","source":"NERDataset -   returns for every item all the information in the encodings as a dictionary, and adds an additional key with the labels.  \n\nThis NERDataset class provides a convenient interface for working with NER data within the torch and torchvision packages. It allows you to use iterators and other functions from the torch.utils.data module to efficiently train and evaluate a model on a NER dataset.\n","metadata":{}},{"cell_type":"code","source":"import torch\n\nclass NERDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    # get item by index\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n    \n    # get len of elements\n    def __len__(self):\n        return len(self.labels)\n    \n\ntrain_dataset = NERDataset(train_texts_encoded, train_labels)\ndev_dataset = NERDataset(dev_texts_encoded, dev_labels)\ntest_dataset = NERDataset(test_texts_encoded, test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:09:01.331343Z","iopub.execute_input":"2023-05-21T12:09:01.331710Z","iopub.status.idle":"2023-05-21T12:09:04.607293Z","shell.execute_reply.started":"2023-05-21T12:09:01.331679Z","shell.execute_reply":"2023-05-21T12:09:04.606310Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation of the results:\nAccuracy score on all labels, excluding `-100`. In named entity recognition, accuracy tends to be very high, because most tokens are not part of an entity mention. Therefore I also compute precision, recall and F-score on the entity labels only (excluding label `0`). This is a much better measure of the model's success at identifying entities.","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n\n    flat_labels, flat_preds = [], []\n    flat_ent_labels, flat_ent_preds = [], []\n    \n    for label_row, pred_row in zip(labels, preds):\n        for label, pred_label in zip(label_row, pred_row):\n            # ignore -100 labels\n            if label != -100:\n                flat_labels.append(label)\n                flat_preds.append(pred_label)\n                if label != 0 or pred_label != 0:\n                    flat_ent_labels.append(label)\n                    flat_ent_preds.append(pred_label)\n                    \n        \n    precision, recall, f1, _ = precision_recall_fscore_support(flat_ent_labels, flat_ent_preds, average='micro')\n    acc = accuracy_score(flat_labels, flat_preds)\n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:53:53.153155Z","iopub.execute_input":"2023-05-21T12:53:53.153628Z","iopub.status.idle":"2023-05-21T12:53:53.163599Z","shell.execute_reply.started":"2023-05-21T12:53:53.153594Z","shell.execute_reply":"2023-05-21T12:53:53.162608Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"markdown","source":"This is easy to do with the `Trainer` class of the `transformers` package","metadata":{}},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    print(\"CUDA is available.\")\nelse:\n    print(\"CUDA is not available.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:55:03.783690Z","iopub.execute_input":"2023-05-21T12:55:03.784199Z","iopub.status.idle":"2023-05-21T12:55:03.874550Z","shell.execute_reply.started":"2023-05-21T12:55:03.784161Z","shell.execute_reply":"2023-05-21T12:55:03.873605Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"CUDA is available.\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:55:46.014364Z","iopub.execute_input":"2023-05-21T12:55:46.014767Z","iopub.status.idle":"2023-05-21T12:55:46.023195Z","shell.execute_reply.started":"2023-05-21T12:55:46.014735Z","shell.execute_reply":"2023-05-21T12:55:46.022014Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments, AutoModelForTokenClassification, BertForTokenClassification\n\nmodel = AutoModelForTokenClassification.from_pretrained(MODEL, num_labels=len(all_labels))\nmodel.to(device)\n\ntraining_args = TrainingArguments(\n    output_dir='./results_NER',          \n    num_train_epochs=4,              \n    per_device_train_batch_size=8,  # batch size per device during training\n    per_device_eval_batch_size=8,   # batch size for evaluation\n    warmup_steps=int(len(train_dataset)/8),  # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    evaluation_strategy=\"steps\",\n    eval_steps=200,\n    save_steps=200,\n    save_total_limit=10,\n    load_best_model_at_end=True,\n    no_cuda=False\n)\n\ntrainer = Trainer(\n    model=model,                        \n    args=training_args,                 \n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,         \n    eval_dataset=dev_dataset,            \n)\n\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:00:53.988623Z","iopub.execute_input":"2023-05-21T13:00:53.989057Z","iopub.status.idle":"2023-05-21T13:09:33.979675Z","shell.execute_reply.started":"2023-05-21T13:00:53.989024Z","shell.execute_reply":"2023-05-21T13:09:33.978716Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230521_130101-ukigki9w</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/my_team_one/huggingface/runs/ukigki9w' target=\"_blank\">lilac-frog-2</a></strong> to <a href='https://wandb.ai/my_team_one/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/my_team_one/huggingface' target=\"_blank\">https://wandb.ai/my_team_one/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/my_team_one/huggingface/runs/ukigki9w' target=\"_blank\">https://wandb.ai/my_team_one/huggingface/runs/ukigki9w</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1360' max='1360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1360/1360 07:54, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>No log</td>\n      <td>0.066694</td>\n      <td>0.978430</td>\n      <td>0.760093</td>\n      <td>0.760093</td>\n      <td>0.760093</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>No log</td>\n      <td>0.046011</td>\n      <td>0.985523</td>\n      <td>0.832529</td>\n      <td>0.832529</td>\n      <td>0.832529</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.175600</td>\n      <td>0.062417</td>\n      <td>0.983479</td>\n      <td>0.796191</td>\n      <td>0.796191</td>\n      <td>0.796191</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.175600</td>\n      <td>0.045596</td>\n      <td>0.986524</td>\n      <td>0.837607</td>\n      <td>0.837607</td>\n      <td>0.837607</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.026600</td>\n      <td>0.041772</td>\n      <td>0.987734</td>\n      <td>0.853073</td>\n      <td>0.853073</td>\n      <td>0.853073</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.026600</td>\n      <td>0.052610</td>\n      <td>0.987317</td>\n      <td>0.849430</td>\n      <td>0.849430</td>\n      <td>0.849430</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1360, training_loss=0.07668719852671904, metrics={'train_runtime': 518.1322, 'train_samples_per_second': 41.943, 'train_steps_per_second': 2.625, 'total_flos': 1530547341755472.0, 'train_loss': 0.07668719852671904, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluating the results","metadata":{}},{"cell_type":"markdown","source":"Finally,I evaluate the model on the test dataset.","metadata":{}},{"cell_type":"code","source":"trainer.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:10:21.609585Z","iopub.execute_input":"2023-05-21T13:10:21.610153Z","iopub.status.idle":"2023-05-21T13:10:27.733615Z","shell.execute_reply.started":"2023-05-21T13:10:21.610113Z","shell.execute_reply":"2023-05-21T13:10:27.732254Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [59/59 00:05]\n    </div>\n    "},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.04833297058939934,\n 'eval_accuracy': 0.9847328244274809,\n 'eval_f1': 0.8363954505686789,\n 'eval_precision': 0.8363954505686789,\n 'eval_recall': 0.8363954505686789,\n 'eval_runtime': 6.0943,\n 'eval_samples_per_second': 154.406,\n 'eval_steps_per_second': 9.681,\n 'epoch': 4.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Based on the evaluation metrics, the BERT pretrained model performs well on the NCBI dataset corpus. Here are the key observations:\n\n- Evaluation Loss: The evaluation loss of 0.048 indicates the average loss of the model's predictions on the evaluation dataset. A lower evaluation loss suggests that the model is making more accurate predictions.\n\n- Evaluation Accuracy: The evaluation accuracy of 0.985 indicates the proportion of correctly predicted tokens in the evaluation dataset. A higher accuracy indicates that the model is performing well in correctly identifying and classifying tokens.\n\n- Evaluation F1 Score: The evaluation F1 score of 0.836 measures the model's balance between precision and recall. It considers both false positives and false negatives, and a higher F1 score indicates a better overall performance.\n\n- Evaluation Precision: The evaluation precision of 0.836 represents the proportion of correctly predicted positive (named entity) tokens out of all predicted positive tokens. It measures the model's ability to avoid false positives.\n\n- Evaluation Recall: The evaluation recall of 0.836 represents the proportion of correctly predicted positive (named entity) tokens out of all true positive tokens. It measures the model's ability to capture all positive tokens.\n\n- Evaluation Samples per Second: The evaluation samples per second value of 154.406 represents the number of samples processed by the model per second during evaluation. \n\n\n### It can be concluded that the BERT pretrained model demonstrates good performance on the NCBI dataset corpus, achieving high accuracy, precision, recall, and F1 score. The model appears to have learned the patterns in the data and is capable of identifying named entities effectively.","metadata":{}},{"cell_type":"markdown","source":"For inference, I load the model and combine it with the tokenizer in an `ner` pipeline - easily label new texts and inspect the results.","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nmodel = AutoModelForTokenClassification.from_pretrained(\"/results_NER\")\nnlp = pipeline(\"ner\", tokenizer=tokenizer, model=model)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:20:53.785959Z","iopub.execute_input":"2023-05-21T13:20:53.786380Z","iopub.status.idle":"2023-05-21T13:20:53.794158Z","shell.execute_reply.started":"2023-05-21T13:20:53.786347Z","shell.execute_reply":"2023-05-21T13:20:53.792968Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"print(dataset[\"test\"][1])\nnlp(dataset[\"test\"][1][\"tokens\"])","metadata":{},"execution_count":19,"outputs":[{"name":"stdout","output_type":"stream","text":"{'id': '1', 'ner_tags': [1, 2, 2, 0, 1, 2, 2, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Ataxia', '-', 'telangiectasia', '(', 'A', '-', 'T', ')', 'is', 'a', 'recessive', 'multi', '-', 'system', 'disorder', 'caused', 'by', 'mutations', 'in', 'the', 'ATM', 'gene', 'at', '11q22', '-', 'q23', '(', 'ref', '.', '3', ')', '.']}\n"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":["[[{'word': 'ataxia',\n","   'score': 0.9266947507858276,\n","   'entity': 'LABEL_1',\n","   'index': 1,\n","   'start': 0,\n","   'end': 6}],\n"," [{'word': '-',\n","   'score': 0.9998806715011597,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': 'telangiect',\n","   'score': 0.9920430779457092,\n","   'entity': 'LABEL_1',\n","   'index': 1,\n","   'start': 0,\n","   'end': 10},\n","  {'word': '##asia',\n","   'score': 0.9963495135307312,\n","   'entity': 'LABEL_2',\n","   'index': 2,\n","   'start': 10,\n","   'end': 14}],\n"," [{'word': '(',\n","   'score': 0.9998924732208252,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': 'a',\n","   'score': 0.9997237324714661,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': '-',\n","   'score': 0.9998806715011597,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': 't',\n","   'score': 0.9996972680091858,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': ')',\n","   'score': 0.99981689453125,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': 'is',\n","   'score': 0.9998725056648254,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 2}],\n"," [{'word': 'a',\n","   'score': 0.9997237324714661,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': 'recessive',\n","   'score': 0.9997004270553589,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 9}],\n"," [{'word': 'multi',\n","   'score': 0.9998838901519775,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 5}],\n"," [{'word': '-',\n","   'score': 0.9998806715011597,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': 'system',\n","   'score': 0.9998276829719543,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 6}],\n"," [{'word': 'disorder',\n","   'score': 0.9770255088806152,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 8}],\n"," [{'word': 'caused',\n","   'score': 0.9998867511749268,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 6}],\n"," [{'word': 'by',\n","   'score': 0.9997820258140564,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 2}],\n"," [{'word': 'mutations',\n","   'score': 0.9998729825019836,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 9}],\n"," [{'word': 'in',\n","   'score': 0.9997439384460449,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 2}],\n"," [{'word': 'the',\n","   'score': 0.999903678894043,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 3}],\n"," [{'word': 'atm',\n","   'score': 0.9996559023857117,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 3}],\n"," [{'word': 'gene',\n","   'score': 0.9998477697372437,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 4}],\n"," [{'word': 'at',\n","   'score': 0.9990025758743286,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 2}],\n"," [{'word': '11',\n","   'score': 0.9999526143074036,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 2},\n","  {'word': '##q2',\n","   'score': 0.999955415725708,\n","   'entity': 'LABEL_0',\n","   'index': 2,\n","   'start': 2,\n","   'end': 4},\n","  {'word': '##2',\n","   'score': 0.9999492764472961,\n","   'entity': 'LABEL_0',\n","   'index': 3,\n","   'start': 4,\n","   'end': 5}],\n"," [{'word': '-',\n","   'score': 0.9998806715011597,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': 'q2',\n","   'score': 0.999927282333374,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 2},\n","  {'word': '##3',\n","   'score': 0.9999404549598694,\n","   'entity': 'LABEL_0',\n","   'index': 2,\n","   'start': 2,\n","   'end': 3}],\n"," [{'word': '(',\n","   'score': 0.9998924732208252,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': 'ref',\n","   'score': 0.9997204542160034,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 3}],\n"," [{'word': '.',\n","   'score': 0.9999040961265564,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': '3',\n","   'score': 0.999706506729126,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': ')',\n","   'score': 0.99981689453125,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}],\n"," [{'word': '.',\n","   'score': 0.9999040961265564,\n","   'entity': 'LABEL_0',\n","   'index': 1,\n","   'start': 0,\n","   'end': 1}]]"]},"metadata":{}}]},{"cell_type":"markdown","source":"# Conclusion:\n\n### The model identified several entities related to a genetic disorder called ataxia-telangiectasia. It recognized terms such as \"ataxia,\" \"telangiectasia,\" \"recessive,\" \"multi-system disorder,\" and \"mutations in the ATM gene at 11q22.\" These findings suggest that the model is able to accurately identify and label relevant medical entities associated with ataxia-telangiectasia.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}